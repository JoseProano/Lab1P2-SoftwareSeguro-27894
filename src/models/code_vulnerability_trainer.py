"""
Advanced Code Vulnerability Detection Training
Re-trains models to detect vulnerabilities IN SOURCE CODE (not just CVE descriptions)
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score
import joblib
from pathlib import Path
from loguru import logger
import re
from typing import List, Dict, Tuple


class CodeVulnerabilityTrainer:
    """Train ML models to detect vulnerabilities in source code"""
    
    def __init__(self, output_dir: str = "./models"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        self.code_vectorizer = TfidfVectorizer(
            max_features=5000,
            ngram_range=(1, 3),
            min_df=2,
            analyzer='char_wb'  # Character-level for code patterns
        )
        self.scaler = StandardScaler()
        
    def generate_vulnerable_code_samples(self) -> pd.DataFrame:
        """Generate synthetic vulnerable code samples based on CVE patterns"""
        
        vulnerable_samples = []
        
        # SQL Injection patterns
        sql_injection_patterns = [
            'query = "SELECT * FROM users WHERE id = \'" + user_input + "\'"',
            'cursor.execute("SELECT * FROM " + table_name)',
            'db.query(f"DELETE FROM users WHERE id={user_id}")',
            'sql = "INSERT INTO logs VALUES (\'" + data + "\')"',
            'connection.execute(query_string % values)',
        ]
        
        # Command Injection patterns
        command_injection_patterns = [
            'os.system("ls " + user_input)',
            'subprocess.call("ping " + ip_address, shell=True)',
            'exec("import " + module_name)',
            'eval(request.POST["code"])',
            'os.popen("tar -xzf " + filename).read()',
        ]
        
        # Path Traversal patterns
        path_traversal_patterns = [
            'open("/var/www/" + filename)',
            'with open(base_path + user_file) as f:',
            'File.read("uploads/" + request["file"])',
            'fs.readFileSync(path.join(__dirname, req.query.path))',
        ]
        
        # Insecure Deserialization
        deserialization_patterns = [
            'pickle.loads(request.data)',
            'yaml.load(user_config)',
            'unserialize($_POST["data"])',
            'JSON.parse(untrusted_input)',
        ]
        
        # Hard-coded Secrets
        hardcoded_secrets = [
            'PASSWORD = "admin123"',
            'API_KEY = "sk-1234567890abcdef"',
            'aws_secret = "wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY"',
            'db_password = "P@ssw0rd"',
        ]
        
        # Weak Cryptography
        weak_crypto = [
            'hashlib.md5(password.encode()).hexdigest()',
            'crypto.createHash("sha1").update(data)',
            'MessageDigest.getInstance("MD5")',
        ]
        
        # Build dataset
        for pattern in sql_injection_patterns:
            vulnerable_samples.append({
                'code': pattern,
                'vulnerability_type': 'SQL Injection',
                'severity': 'CRITICAL',
                'cwe': 'CWE-89',
                'is_vulnerable': 1
            })
        
        for pattern in command_injection_patterns:
            vulnerable_samples.append({
                'code': pattern,
                'vulnerability_type': 'Command Injection',
                'severity': 'CRITICAL',
                'cwe': 'CWE-78',
                'is_vulnerable': 1
            })
            
        for pattern in path_traversal_patterns:
            vulnerable_samples.append({
                'code': pattern,
                'vulnerability_type': 'Path Traversal',
                'severity': 'HIGH',
                'cwe': 'CWE-22',
                'is_vulnerable': 1
            })
            
        for pattern in deserialization_patterns:
            vulnerable_samples.append({
                'code': pattern,
                'vulnerability_type': 'Insecure Deserialization',
                'severity': 'CRITICAL',
                'cwe': 'CWE-502',
                'is_vulnerable': 1
            })
            
        for pattern in hardcoded_secrets:
            vulnerable_samples.append({
                'code': pattern,
                'vulnerability_type': 'Hard-coded Secrets',
                'severity': 'HIGH',
                'cwe': 'CWE-798',
                'is_vulnerable': 1
            })
            
        for pattern in weak_crypto:
            vulnerable_samples.append({
                'code': pattern,
                'vulnerability_type': 'Weak Cryptography',
                'severity': 'MEDIUM',
                'cwe': 'CWE-327',
                'is_vulnerable': 1
            })
        
        # Safe code samples (negatives)
        safe_samples = [
            {'code': 'cursor.execute("SELECT * FROM users WHERE id = ?", (user_id,))', 'is_vulnerable': 0},
            {'code': 'subprocess.run(["ls", "-la"], capture_output=True)', 'is_vulnerable': 0},
            {'code': 'filepath = os.path.join(BASE_DIR, os.path.basename(filename))', 'is_vulnerable': 0},
            {'code': 'data = json.loads(request.body)', 'is_vulnerable': 0},
            {'code': 'password = os.environ.get("DATABASE_PASSWORD")', 'is_vulnerable': 0},
            {'code': 'hashlib.sha256(password.encode()).hexdigest()', 'is_vulnerable': 0},
            {'code': 'def calculate_total(items): return sum(item.price for item in items)', 'is_vulnerable': 0},
            {'code': 'user = User.objects.filter(email=email).first()', 'is_vulnerable': 0},
            {'code': 'with open(safe_file, "r") as f: content = f.read()', 'is_vulnerable': 0},
            {'code': 'import logging; logger = logging.getLogger(__name__)', 'is_vulnerable': 0},
        ]
        
        for sample in safe_samples:
            sample['vulnerability_type'] = 'None'
            sample['severity'] = 'NONE'
            sample['cwe'] = 'N/A'
        
        df = pd.DataFrame(vulnerable_samples + safe_samples * 5)  # Balance dataset
        return df
    
    def extract_code_features(self, code: str) -> Dict[str, float]:
        """Extract numerical features from code"""
        features = {}
        
        # Length features
        features['code_length'] = len(code)
        features['num_lines'] = code.count('\n') + 1
        features['avg_line_length'] = len(code) / max(features['num_lines'], 1)
        
        # Dangerous patterns
        features['has_sql_keywords'] = int(bool(re.search(r'SELECT|INSERT|UPDATE|DELETE|DROP', code, re.I)))
        features['has_exec_eval'] = int(bool(re.search(r'\bexec\b|\beval\b', code, re.I)))
        features['has_system_call'] = int(bool(re.search(r'system\(|popen\(|shell=True', code, re.I)))
        features['has_file_ops'] = int(bool(re.search(r'open\(|read\(|write\(', code, re.I)))
        features['has_network'] = int(bool(re.search(r'socket\(|request\.|urllib', code, re.I)))
        features['has_crypto'] = int(bool(re.search(r'md5|sha1|hashlib|crypto', code, re.I)))
        features['has_pickle'] = int(bool(re.search(r'pickle|yaml\.load|unserialize', code, re.I)))
        
        # String concatenation (risky)
        features['has_string_concat'] = int(bool(re.search(r'\+\s*["\']|["\']\\s*\+', code)))
        features['has_f_string'] = int(bool(re.search(r'f["\']', code)))
        features['has_format'] = int(bool(re.search(r'\.format\(|%\s*\(', code)))
        
        # Security indicators
        features['has_password'] = int(bool(re.search(r'password|passwd|pwd|secret|key', code, re.I)))
        features['has_hardcoded_string'] = int(bool(re.search(r'=\s*["\'][^"\']{8,}["\']', code)))
        features['has_path_traversal'] = int(bool(re.search(r'\.\./|\.\.\\', code)))
        
        return features
    
    def train_models(self):
        """Train multiple models for code vulnerability detection"""
        
        logger.info("ðŸ”„ Generating training dataset from vulnerability patterns...")
        df = self.generate_vulnerable_code_samples()
        logger.info(f"Generated {len(df)} code samples ({df['is_vulnerable'].sum()} vulnerable)")
        
        # Extract features
        logger.info("Extracting code features...")
        numerical_features = df['code'].apply(self.extract_code_features).apply(pd.Series)
        text_features = self.code_vectorizer.fit_transform(df['code'])
        
        # Combine features - convert to numpy array to avoid feature name warnings
        X_numerical = self.scaler.fit_transform(numerical_features.values)  # Use .values to get numpy array
        X_text = text_features.toarray()
        X = np.hstack([X_numerical, X_text])
        y = df['is_vulnerable'].values
        
        # Split data
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        logger.info(f"Training set: {len(X_train)}, Test set: {len(X_test)}")
        
        # Train models
        models = {
            'random_forest': RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42),
            'decision_tree': DecisionTreeClassifier(max_depth=15, random_state=42),
            'gradient_boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),
            'svm': SVC(kernel='rbf', probability=True, random_state=42),
            'neural_network': MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)
        }
        
        results = {}
        
        for name, model in models.items():
            logger.info(f"\n{'='*60}")
            logger.info(f"Training {name}...")
            model.fit(X_train, y_train)
            
            # Evaluate
            y_pred = model.predict(X_test)
            y_pred_proba = model.predict_proba(X_test)[:, 1]
            
            accuracy = (y_pred == y_test).mean()
            auc = roc_auc_score(y_test, y_pred_proba)
            
            logger.info(f"Accuracy: {accuracy:.4f}")
            logger.info(f"AUC-ROC: {auc:.4f}")
            logger.info(f"\nClassification Report:\n{classification_report(y_test, y_pred)}")
            
            # Save model
            model_path = self.output_dir / f'{name}_code_scanner.joblib'
            joblib.dump(model, model_path)
            logger.info(f"âœ… Model saved: {model_path}")
            
            results[name] = {'accuracy': accuracy, 'auc': auc}
        
        # Save preprocessors
        joblib.dump(self.code_vectorizer, self.output_dir / 'code_vectorizer.joblib')
        joblib.dump(self.scaler, self.output_dir / 'code_scaler.joblib')
        
        # Save feature extractor reference
        import pickle
        with open(self.output_dir / 'feature_extractor.pkl', 'wb') as f:
            pickle.dump(self.extract_code_features, f)
        
        logger.info(f"\n{'='*60}")
        logger.info("âœ… All models trained and saved!")
        logger.info(f"\nModel Performance Summary:")
        for name, metrics in results.items():
            logger.info(f"{name:20s}: Accuracy={metrics['accuracy']:.4f}, AUC={metrics['auc']:.4f}")
        
        return results


if __name__ == "__main__":
    trainer = CodeVulnerabilityTrainer()
    trainer.train_models()
